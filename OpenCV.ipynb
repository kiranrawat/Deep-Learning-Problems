{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# butterfly = 'https://i.pinimg.com/originals/36/43/18/3643186bc7e37b00509ec352cf9b7bfc.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(filename)\n",
    "# img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataTypes and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1 1 1]\n",
      "[65535 65535 65535]\n",
      "[255 200   0]\n"
     ]
    }
   ],
   "source": [
    "img1 = np.zeros([150,200,1], 'uint8')\n",
    "cv2.imshow(\"Black\", img1)\n",
    "print(img1[0,0,:])\n",
    "\n",
    "img2 = np.ones([150,200,3], 'uint8')\n",
    "cv2.imshow(\"Ones\", img2)\n",
    "print(img2[0,0,:])\n",
    "\n",
    "white = np.ones([150,200,3], 'uint16') #16 bit line image\n",
    "white *= (2**16 - 1)\n",
    "cv2.imshow(\"White\", white)\n",
    "print(white[0,0,:])\n",
    "\n",
    "color = img2.copy() #creating a deep copy of an image #two are not connected to each other at all\n",
    "color[:,:] = (255,200,0) #BGR format all blue pixes\n",
    "cv2.imshow(\"Blue\", color)\n",
    "print(color[0,0,:])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Types and Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 550, 3)\n"
     ]
    }
   ],
   "source": [
    "color = cv2.imread(\"butterfly.jpg\", 1)\n",
    "cv2.imshow(\"Image\", color)\n",
    "cv2.moveWindow(\"Image\",0,0)\n",
    "print(color.shape)\n",
    "height,width,channels = color.shape\n",
    "\n",
    "b,g,r = cv2.split(color)\n",
    "\n",
    "rgb_split = np.empty([height, width*3, 3], 'uint8')\n",
    "\n",
    "rgb_split[:, 0:width] = cv2.merge([b,b,b])\n",
    "rgb_split[:, width:width*2]= cv2.merge([g,g,g])\n",
    "rgb_split[:, width*2:width*3]= cv2.merge([r,r,r])\n",
    "\n",
    "cv2.imshow(\"Channels\",rgb_split)\n",
    "cv2.moveWindow(\"Channels\",0,height)\n",
    "\n",
    "hsv = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(hsv)\n",
    "hsv_split = np.concatenate((h,s,v), axis=1)\n",
    "cv2.imshow(\"Split hsv\", hsv_split)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Manupulation & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = cv2.imread(\"butterfly.jpg\", 1)\n",
    "\n",
    "gray = cv2.cvtColor(color, cv2.COLOR_RGB2GRAY)\n",
    "cv2.imwrite(\"gray.jpg\", gray)\n",
    "\n",
    "b = color[:,:,0]\n",
    "g = color[:,:,1]\n",
    "r = color[:,:,2]\n",
    "\n",
    "rgba = cv2.merge((b,g,r,g)) #4th channel is to add transparancy layer\n",
    "cv2.imwrite(\"rgba.png\", rgba) #using png here as JPEG doesnot support image transparency \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Blur, Dilation & Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these filters can be combined and used together to remove the noise\n",
    "image = cv2.imread(\"thresh.jpg\")\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "blur = cv2.GaussianBlur(image, (5,55), 0)\n",
    "cv2.imshow(\"Blur\", blur)\n",
    "\n",
    "kernel = np.ones((5,5), 'uint8') #finding the kernel\n",
    "\n",
    "dilate = cv2.dilate(image, kernel, iterations=1)\n",
    "erode = cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow(\"dilate\", dilate)\n",
    "cv2.imshow(\"erode\", erode)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Scaling and Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"players.jpg\", 1)\n",
    "\n",
    "# Scale\n",
    "img_half = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n",
    "img_stretch = cv2.resize(img, (600,600))\n",
    "img_stretch_near = cv2.resize(img, (600,600), interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "cv2.imshow(\"half\", img_half)\n",
    "cv2.imshow(\"stretch\", img_stretch)\n",
    "cv2.imshow(\"strech near\", img_stretch_near)\n",
    "\n",
    "#Rotation\n",
    "\n",
    "M = cv2.getRotationMatrix2D((0,0), -30, 1)\n",
    "rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "cv2.imshow(\"rotated\", rotated)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pressed 332 156\n",
      "pressed 351 256\n",
      "pressed 339 199\n",
      "pressed 339 192\n",
      "pressed 335 203\n",
      "pressed 505 88\n",
      "pressed 180 126\n",
      "pressed 155 221\n",
      "pressed 117 310\n",
      "pressed 453 266\n",
      "pressed 521 230\n",
      "pressed 321 221\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#circle color and width\n",
    "color = (0,255,0)\n",
    "line_width = 3\n",
    "radius = 100\n",
    "point = (0,0)\n",
    "\n",
    "def click(event, x, y, flags, param):\n",
    "    global point, pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"pressed\", x, y)\n",
    "        point = (x,y)\n",
    " \n",
    "cv2.namedWindow(\"frame\")\n",
    "cv2.setMouseCallback(\"frame\", click)\n",
    "\n",
    "#0xFF only needed if you r using 64 but machine\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    cv2.circle(frame, point, radius, color, line_width)\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    \n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
