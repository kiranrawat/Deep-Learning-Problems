{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template mathcing is readily available and straightfoward method in feature detection.\n",
    "The way template matching works, is it searches for a similar pattern between two images. \n",
    "This is accomplished by taking a reference image, called a template and sliding it around the other comparison image, taking a difference at every position.\n",
    "The result, is a black and white gray scale image with varying intensities showing how well it matched at each position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46597495675086975 (132, 243)\n"
     ]
    }
   ],
   "source": [
    "template = cv2.imread('template.jpg', 0)\n",
    "frame = cv2.imread('players.jpg', 0)\n",
    "\n",
    "cv2.imshow('Frame', frame)\n",
    "cv2.imshow('Template', template)\n",
    "\n",
    "#Matching template with source image, TM_CCOEFF_NORMED is one of the different mehtods of template matching\n",
    "result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "print(max_val, max_loc)\n",
    "cv2.circle(result, max_loc, 15, 255, 2) #visualizing the location, radius, color,line thickness of 2\n",
    "\n",
    "\n",
    "cv2.imshow('Matching', result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Har Cascading\n",
    "\n",
    "Haar cascade classifiers, a form of future-based machine learning. It works by first training a classifier with set of labeled positive and negatives. Or in other words, indicating to the classifier that these are sets of images that have faces and these are sets of images that don't have faces. This classifier then learns from the set by understanding and extracting features from all the images. For example, it may naturally learn that the region of the eye is as typically darker than the region of the cheeks below and may use that as one of its thousands of indicators that help understand whether not a particular region of interest, or ROI, is a face or not. After the training is completed, and a classifier is defined, we use the classifier in a cascaded manner to run through all the feature checks. This cascade method works like a waterfall, where you apply the fastest and most general checks first in order to quickly rule out areas that are definitely not matching a face without spending too much computational time. As it becomes more refined and goes through more classifiers, it gets more and more sure that the region of interest is actually a face. If it gets through all the cascaded classifiers, it is then marked as a valid face and outputs the bounding blocks. When we run the face detection algorithm and open CV, using the training data, we essentially leverage the already trained information into a cascade classifier which would then output the set of found faces and the regions of interests. Note however, is not always perfect. And is possible that there will still be false positives and false negatives. Since your training data is rarely ever exactly the same as the applied data, you always are at risk at false negatives or positives. But there are parameters to tweak the classifier to make it more accurate for the particular situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8011687d5047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/faces.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'harcascade-classifier/haarcascade_frontalface_default.xml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('images/faces.jpeg', 1)\n",
    "cv2.imshow(\"Original\", img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "path_xml = 'harcascade-classifier/haarcascade_frontalface_default.xml'\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(path_xml)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.05, minNeighbours=5, minSize = (40,40))\n",
    "print(len(faces))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
